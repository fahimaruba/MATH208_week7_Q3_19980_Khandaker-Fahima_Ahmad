import numpy as np
import matplotlib.pyplot as plt

# Given dataset
X = np.array([2, 3, 4, 5, 6, 7, 8, 9, 10, 11])
Y = np.array([30, 25, 95, 115, 265, 325, 570, 700, 1085, 1300])

# Calculate the values of ùëè1 (slope) and ùëè0 (intercept)
n = len(X)
X_mean = np.mean(X)
Y_mean = np.mean(Y)

b1 = np.sum((X - X_mean) * (Y - Y_mean)) / np.sum((X - X_mean) ** 2)
b0 = Y_mean - b1 * X_mean

# Calculate the coefficient of linear correlation (r)
r = np.corrcoef(X, Y)[0, 1]

# Plot the curve of X vs. Y and the straight fitting line
print(b1)
print(b0)
plt.scatter(X, Y, color='blue', label='Data Points')
plt.plot(X, b0 + b1 * X, color='red', label=f'Linear Fit (r = {r:.4f})')
plt.xlabel('X')
plt.ylabel('Y')
plt.legend()
plt.grid()

plt.show()

# Determine whether a linear model is appropriate
# You can evaluate the quality of the fit by looking at the value of r.
# If r is very close to +1, it indicates a strong linear relationship.

# However, from the visualization of the data, it seems that the linear fit may not be the best model
# as there might be some curvature in the data. You can explore other types of regression models
# like polynomial regression, exponential regression, or other non-linear models depending on the data pattern.
